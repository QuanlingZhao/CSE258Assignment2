{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SlHADAO-FnQ_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "from collections import defaultdict, OrderedDict\n",
        "from sklearn import metrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPPO2NYqJF8C",
        "outputId": "fd2ffcf0-ed2a-4d13-ff8f-2ea8d4b1ce0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Torch 1.12.1 CUDA None\n",
            "Device: cuda:0\n",
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Tue_Mar__8_18:18:20_PST_2022\n",
            "Cuda compilation tools, release 11.6, V11.6.124\n",
            "Build cuda_11.6.r11.6/compiler.31057947_0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(False, device(type='cpu'))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Torch', torch.__version__, 'CUDA', torch.version.cuda)\n",
        "print('Device:', torch.device('cuda:0'))\n",
        "\n",
        "!nvcc --version\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.is_available(), device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "U7EsH32EFnRA"
      },
      "outputs": [],
      "source": [
        "config = {}\n",
        "\n",
        "NUM_TARGETS= 3\n",
        "\n",
        "USER_PATHWAY  = [256, 128, 64]\n",
        "ITEM_PATHWAY = [256, 128, 64]\n",
        "COMBINED_PATHWAY = [256, 128, 64, 16]\n",
        "\n",
        "EMBED_DIM = 10\n",
        "NUM_ITEM_EMBED = 1378\n",
        "NUM_USER_EMBED = 47958\n",
        "NUM_CUPSIZE_EMBED =  12\n",
        "NUM_CATEGORY_EMBED = 7\n",
        "\n",
        "NUM_USER_NUMERIC = 5\n",
        "NUM_ITEM_NUMERIC = 2\n",
        "\n",
        "DROPOUT = 0.3\n",
        "\n",
        "EPOCHS = 1\n",
        "LR = 0.001\n",
        "WEIGHT_DECAY = 0.0001\n",
        "BATCH_SIZE = 128\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ModCloth(torch.utils.data.Dataset):\n",
        "    def __init__(self,datapath):\n",
        "        self.data = pd.read_csv(datapath)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        r = self.data.iloc[idx,:]\n",
        "\n",
        "        return {\n",
        "            \"user_id\" : np.array(r['user_id'], dtype=np.int64),\n",
        "            \"cup_size\" : np.array(r['cup_size'], dtype=np.int64),\n",
        "            \"user_numeric\" : np.array([r['waist'], r['hips'], r['bra_size'], r['height'], r['shoe_size']], dtype=np.float32),\n",
        "            \"item_id\" : np.array(r['item_id'], dtype = np.int64),\n",
        "            \"category\" :np.array(r['category'], dtype = np.int64),\n",
        "            \"item_numeric\" : np.array([r['size'], r['quality']], dtype=np.float32),\n",
        "            \"fit\" : np.array(r['fit'], dtype=np.int64)\n",
        "        }\n",
        "\n",
        "datasets = OrderedDict()\n",
        "splits = ['train', 'valid']\n",
        "datasets['train'] =  ModCloth(\"data/modcloth_final_data_processed_train.csv\")\n",
        "datasets['valid'] =  ModCloth(\"data/modcloth_final_data_processed_valid.csv\")\n",
        "datasets['test'] = ModCloth(\"data/modcloth_final_data_processed_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "0vxnymEpFnRD"
      },
      "outputs": [],
      "source": [
        "# macro - Calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account\n",
        "# weighted - Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label). This alters ‘macro’ to account for label imbalance; it can result in an F-score that is not between precision and recall.\n",
        "\n",
        "def compute_metrics(target, pred_probs, averaging = \"macro\"):\n",
        "\n",
        "    pred_labels = pred_probs.argmax(-1)\n",
        "    precision = metrics.precision_score(target, pred_labels, average=averaging)\n",
        "    recall = metrics.recall_score(target, pred_labels, average=averaging)\n",
        "    f1_score = metrics.f1_score(target, pred_labels, average=averaging)\n",
        "    accuracy = metrics.accuracy_score(target, pred_labels)\n",
        "    auc = metrics.roc_auc_score(target, pred_probs, average=averaging, multi_class=\"ovr\")\n",
        "\n",
        "    return precision, recall, f1_score, accuracy, auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Base(nn.Module):\n",
        "    def __init__(self, user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
        "        super().__init__()\n",
        "       \n",
        "        self.user_pathway = user_pathway\n",
        "        self.item_pathway = item_pathway\n",
        "        self.combined_pathway = combined_pathway\n",
        "        self.embedding_dim = embed_dim\n",
        "\n",
        "        self.user_embedding = nn.Embedding(num_user_embed, embed_dim, max_norm=1.0 )\n",
        "        self.cup_size_embedding = nn.Embedding(num_cupsize_embed, embed_dim, max_norm=1.0 )\n",
        "        self.item_embedding = nn.Embedding(num_item_embed, embed_dim, max_norm=1.0 )\n",
        "        self.category_embedding = nn.Embedding(num_category_embed, embed_dim, max_norm=1.0 )\n",
        "\n",
        "\n",
        "    def forward(self, batch_input):\n",
        "        # Customer Pathway\n",
        "        user_emb = self.user_embedding(batch_input[\"user_id\"])\n",
        "        cup_size_emb = self.cup_size_embedding(batch_input[\"cup_size\"])\n",
        "        user_representation = torch.cat( [user_emb, cup_size_emb, batch_input[\"user_numeric\"]], dim=-1 )\n",
        "        user_representation = self.user_transform_blocks(user_representation)\n",
        "\n",
        "        # Article Pathway\n",
        "        item_emb = self.item_embedding(batch_input[\"item_id\"])\n",
        "        category_emb = self.category_embedding(batch_input[\"category\"])\n",
        "        item_representation = torch.cat( [item_emb, category_emb, batch_input[\"item_numeric\"]], dim=-1 )\n",
        "        item_representation = self.item_transform_blocks(item_representation)\n",
        "\n",
        "        # Combine the pathways\n",
        "        combined_representation = torch.cat( [user_representation, item_representation], dim=-1 )\n",
        "        combined_representation = self.combined_blocks(combined_representation)\n",
        "\n",
        "        # Output layer of logits\n",
        "        logits = self.hidden2output(combined_representation)\n",
        "        pred_probs = F.softmax(logits, dim=-1)\n",
        "\n",
        "        return logits, pred_probs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SFNet(Base):\n",
        "    def __init__(self, user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
        "        super().__init__(user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout)\n",
        "\n",
        "        # Customer pathway transformation  ==  user_embedding_dim + cup_size_embedding_dim + num_user_numeric_features\n",
        "        user_features_input_size = 2 * self.embedding_dim + NUM_USER_NUMERIC\n",
        "        self.user_pathway.insert(0, user_features_input_size)\n",
        "        self.user_transform_blocks = []\n",
        "        for i in range(1, len(self.user_pathway)):\n",
        "            self.user_transform_blocks.append( SkipBlock( self.user_pathway[i - 1], self.user_pathway[i] ) )\n",
        "            self.user_transform_blocks.append(nn.Dropout(DROPOUT))\n",
        "        self.user_transform_blocks = nn.Sequential(*self.user_transform_blocks)\n",
        "\n",
        "        # Article pathway transformation == item_embedding_dim + category_embedding_dim + num_item_numeric_features\n",
        "        item_features_input_size = 2 * self.embedding_dim + NUM_ITEM_NUMERIC\n",
        "        self.item_pathway.insert(0, item_features_input_size)\n",
        "        self.item_transform_blocks = []\n",
        "        for i in range(1, len(self.item_pathway)):\n",
        "            self.item_transform_blocks.append( SkipBlock( self.item_pathway[i - 1], self.item_pathway[i]) )\n",
        "            self.item_transform_blocks.append(nn.Dropout(DROPOUT))\n",
        "        self.item_transform_blocks = nn.Sequential(*self.item_transform_blocks)\n",
        "\n",
        "        # Combined top layer pathway\n",
        "        # u = output dim of user_transform_blocks, # t = output dim of item_transform_blocks\n",
        "        # Pathway combination through [u, t] # Hence, input dimension will be 2*dim(u)\n",
        "        combined_layer_input_size = 2 * self.user_pathway[-1]\n",
        "        self.combined_pathway.insert(0, combined_layer_input_size)\n",
        "        self.combined_blocks = []\n",
        "        for i in range(1, len(self.combined_pathway)):\n",
        "            self.combined_blocks.append( SkipBlock( self.combined_pathway[i - 1], self.combined_pathway[i]) )\n",
        "            self.combined_blocks.append(nn.Dropout(DROPOUT))\n",
        "        self.combined_blocks = nn.Sequential(*self.combined_blocks)\n",
        "\n",
        "        # Linear transformation from last hidden layer to output\n",
        "        self.hidden2output = nn.Linear(self.combined_pathway[-1], NUM_TARGETS)\n",
        "\n",
        "\n",
        "class SkipBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\" Skip Connection for feed-forward  - ResNet Block \"\"\"\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(input_dim, output_dim)\n",
        "        self.W2 = nn.Linear(output_dim, output_dim)\n",
        "        self.I = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"  z = ReLU(   W2( ReLU( W1(x))) + Projection(x))    \"\"\"\n",
        "        z = relu(self.W2(relu(self.W1(x))) + self.I(x))\n",
        "        return z\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "nP3EpC5EFnRE"
      },
      "outputs": [],
      "source": [
        "class MLP(Base):\n",
        "    def __init__(self,user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout):\n",
        "        super().__init__(user_pathway, item_pathway, combined_pathway, embed_dim, num_item_embed, num_user_embed, num_cupsize_embed, num_category_embed, dropout)\n",
        "\n",
        "        # Customer pathway transformation  ==  user_embedding_dim + cup_size_embedding_dim + num_user_numeric_features\n",
        "        user_features_input_size = 2 * self.embedding_dim + NUM_USER_NUMERIC\n",
        "        self.user_pathway.insert(0, user_features_input_size)\n",
        "        self.user_transform_blocks = []\n",
        "        for i in range(1, len(self.user_pathway)):\n",
        "            self.user_transform_blocks.append( LinearBlock( self.user_pathway[i - 1], self.user_pathway[i] ) )\n",
        "        self.user_transform_blocks = nn.Sequential(*self.user_transform_blocks)\n",
        "\n",
        "        # Article pathway transformation == item_embedding_dim + category_embedding_dim + num_item_numeric_features\n",
        "        item_features_input_size = 2 * self.embedding_dim + NUM_ITEM_NUMERIC\n",
        "        self.item_pathway.insert(0, item_features_input_size)\n",
        "        self.item_transform_blocks = []\n",
        "        for i in range(1, len(self.item_pathway)):\n",
        "            self.item_transform_blocks.append( LinearBlock( self.item_pathway[i - 1], self.item_pathway[i])  )\n",
        "        self.item_transform_blocks = nn.Sequential(*self.item_transform_blocks)\n",
        "\n",
        "        # Combined top layer pathway\n",
        "        # u = output dim of user_transform_blocks, # t = output dim of item_transform_blocks\n",
        "        # Pathway combination through [u, t] # Hence, input dimension will be 4*dim(u)\n",
        "        combined_layer_input_size = 2 * self.user_pathway[-1]\n",
        "        self.combined_pathway.insert(0, combined_layer_input_size)\n",
        "        self.combined_blocks = []\n",
        "        for i in range(1, len(self.combined_pathway)):\n",
        "            self.combined_blocks.append( LinearBlock( self.combined_pathway[i - 1], self.combined_pathway[i]) )\n",
        "        self.combined_blocks = nn.Sequential(*self.combined_blocks)\n",
        "\n",
        "        # Linear transformation from last hidden layer to output\n",
        "        self.hidden2output = nn.Linear(self.combined_pathway[-1], NUM_TARGETS)\n",
        "\n",
        "\n",
        "class LinearBlock(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        \"\"\" Skip Connection for feed-forward  - ResNet Block \"\"\"\n",
        "        super().__init__()\n",
        "        self.W1 = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"  z = ReLU(   W2( ReLU( W1(x))) + Projection(x))    \"\"\"\n",
        "        return relu(self.W1(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "B6QlmtdwFnRK",
        "outputId": "755c9a5a-13de-4e60-b7f5-175024986d75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Number of model parameters: 769673\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = MLP(USER_PATHWAY, ITEM_PATHWAY, COMBINED_PATHWAY, EMBED_DIM, NUM_ITEM_EMBED, NUM_USER_EMBED, NUM_CUPSIZE_EMBED, NUM_CATEGORY_EMBED, DROPOUT)\n",
        "model = model.to(device)\n",
        "\n",
        "# print(\"-\" * 50)\n",
        "# print(model)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of model parameters: {total_params}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "loss_criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay= WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN2h7vipFnRL",
        "outputId": "c67f76a0-7508-4f3c-f5d0-9a6ad5d15374"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN Batch Stats 0/518, Loss=1.06\n",
            "TRAIN Batch Stats 100/518, Loss=0.81\n",
            "TRAIN Batch Stats 200/518, Loss=0.88\n",
            "TRAIN Batch Stats 300/518, Loss=0.73\n",
            "TRAIN Batch Stats 400/518, Loss=0.75\n",
            "TRAIN Batch Stats 500/518, Loss=0.78\n",
            "TRAIN Batch Stats 517/518, Loss=0.79\n",
            "TRAIN Epoch 1 / 1, Mean Total Loss 0.8127315044403076\n",
            "VALID Batch Stats 0/65, Loss=0.69\n",
            "VALID Batch Stats 64/65, Loss=0.80\n",
            "VALID Epoch 1 / 1, Mean Total Loss 0.7955179214477539\n",
            "TRAIN Batch Stats 0/518, Loss=0.82\n",
            "TRAIN Batch Stats 100/518, Loss=0.81\n",
            "TRAIN Batch Stats 200/518, Loss=0.88\n",
            "TRAIN Batch Stats 300/518, Loss=0.77\n",
            "TRAIN Batch Stats 400/518, Loss=0.70\n",
            "TRAIN Batch Stats 500/518, Loss=0.74\n",
            "TRAIN Batch Stats 517/518, Loss=0.86\n",
            "TRAIN Epoch 1 / 1, Mean Total Loss 0.7844616770744324\n",
            "VALID Batch Stats 0/65, Loss=0.66\n",
            "VALID Batch Stats 64/65, Loss=0.77\n",
            "VALID Epoch 1 / 1, Mean Total Loss 0.7659412026405334\n",
            "TRAIN Batch Stats 0/518, Loss=0.70\n",
            "TRAIN Batch Stats 100/518, Loss=0.76\n",
            "TRAIN Batch Stats 200/518, Loss=0.74\n",
            "TRAIN Batch Stats 300/518, Loss=0.83\n",
            "TRAIN Batch Stats 400/518, Loss=0.75\n",
            "TRAIN Batch Stats 500/518, Loss=0.78\n",
            "TRAIN Batch Stats 517/518, Loss=0.87\n",
            "TRAIN Epoch 1 / 1, Mean Total Loss 0.7533168792724609\n",
            "VALID Batch Stats 0/65, Loss=0.60\n",
            "VALID Batch Stats 64/65, Loss=0.72\n",
            "VALID Epoch 1 / 1, Mean Total Loss 0.742369532585144\n"
          ]
        }
      ],
      "source": [
        "step = 0\n",
        "\n",
        "tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    for d in datasets:\n",
        "        for split in splits:\n",
        "            data_loader = DataLoader( dataset=datasets[split], batch_size=BATCH_SIZE, shuffle = (split == \"train\") )\n",
        "\n",
        "            loss_tracker = defaultdict(tensor)\n",
        "\n",
        "            # Enable/Disable Dropout\n",
        "            if split == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                target_tracker = []\n",
        "                pred_tracker = []\n",
        "\n",
        "            for iteration, batch in enumerate(data_loader):\n",
        "\n",
        "                for k, v in batch.items():\n",
        "                    batch[k] = v.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits, pred_probs = model(batch)\n",
        "\n",
        "                # loss calculation\n",
        "                loss = loss_criterion(logits, batch[\"fit\"])   # batch['fit'] are the true labels\n",
        "\n",
        "                # backward + optimization\n",
        "                if split == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    step += 1\n",
        "\n",
        "                # bookkeepeing\n",
        "                loss_tracker[\"Total Loss\"] = torch.cat((loss_tracker[\"Total Loss\"], loss.view(1)))\n",
        "\n",
        "                if iteration % 100 == 0 or iteration + 1 == len(data_loader):\n",
        "                    print(f\"{split.upper()} Batch Stats {iteration}/{len(data_loader)}, Loss={loss.item() :.2f}\")\n",
        "\n",
        "                if split == \"valid\":\n",
        "                    target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
        "                    pred_tracker.append(pred_probs.cpu().data.numpy())\n",
        "\n",
        "            print( f\"{split.upper()} Epoch {epoch + 1} / {EPOCHS}, Mean Total Loss {torch.mean(loss_tracker['Total Loss'])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VopBWrV5FnRM",
        "outputId": "cca1bf4d-a815-4106-cd21-0f962161b485"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preparing test data ...\n",
            "Evaluating model on test data ...\n",
            "--------------------------------------------------\n",
            "Metrics:\n",
            " Precision = 0.53569623951807\n",
            " Recall = 0.6873779296875\n",
            " F1-score = 0.561165759107278\n",
            " Accuracy = 0.6873779296875\n",
            " AUC = 0.6634122911456146\n",
            " \n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "target_tracker = []\n",
        "pred_tracker = []\n",
        "\n",
        "print(\"Preparing test data ...\")\n",
        "\n",
        "data_loader = DataLoader(dataset = datasets['test'], batch_size = BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Evaluating model on test data ...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for iteration, batch in enumerate(data_loader):\n",
        "\n",
        "        for k, v in batch.items():\n",
        "            batch[k] = v.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        _, pred_probs = model(batch)\n",
        "\n",
        "        target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
        "        pred_tracker.append(pred_probs.cpu().data.numpy())\n",
        "\n",
        "target_tracker = np.stack(target_tracker[:-1]).reshape(-1)\n",
        "pred_tracker = np.stack(pred_tracker[:-1], axis=0).reshape(-1, NUM_TARGETS)\n",
        "precision, recall, f1_score, accuracy, auc = compute_metrics(target_tracker, pred_tracker, averaging = \"weighted\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"Metrics:\\n Precision = {precision}\\n Recall = {recall}\\n F1-score = {f1_score}\\n Accuracy = {accuracy}\\n AUC = {auc}\\n \")\n",
        "print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--------------------------------------------------\n",
            "Number of model parameters: 1464421\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "model = SFNet(USER_PATHWAY, ITEM_PATHWAY, COMBINED_PATHWAY, EMBED_DIM, NUM_ITEM_EMBED, NUM_USER_EMBED, NUM_CUPSIZE_EMBED, NUM_CATEGORY_EMBED, DROPOUT)\n",
        "model = model.to(device)\n",
        "\n",
        "# print(\"-\" * 50)\n",
        "# print(model)\n",
        "\n",
        "print(\"-\" * 50)\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of model parameters: {total_params}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "loss_criterion = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR, weight_decay= WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TRAIN Batch Stats 0/518, Loss=1.13\n",
            "TRAIN Batch Stats 100/518, Loss=0.93\n",
            "TRAIN Batch Stats 200/518, Loss=0.80\n",
            "TRAIN Batch Stats 300/518, Loss=0.80\n",
            "TRAIN Batch Stats 400/518, Loss=0.88\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [47], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     35\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> 36\u001b[0m     optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     37\u001b[0m     step \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     39\u001b[0m \u001b[39m# bookkeepeing\u001b[39;00m\n",
            "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[1;32m    158\u001b[0m          grads,\n\u001b[1;32m    159\u001b[0m          exp_avgs,\n\u001b[1;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[1;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[1;32m    162\u001b[0m          state_steps,\n\u001b[1;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m func(params,\n\u001b[1;32m    214\u001b[0m      grads,\n\u001b[1;32m    215\u001b[0m      exp_avgs,\n\u001b[1;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    218\u001b[0m      state_steps,\n\u001b[1;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
            "File \u001b[0;32m~/mambaforge/lib/python3.10/site-packages/torch/optim/adam.py:305\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    303\u001b[0m     denom \u001b[39m=\u001b[39m (max_exp_avg_sqs[i]\u001b[39m.\u001b[39msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    304\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     denom \u001b[39m=\u001b[39m (exp_avg_sq\u001b[39m.\u001b[39;49msqrt() \u001b[39m/\u001b[39m bias_correction2_sqrt)\u001b[39m.\u001b[39madd_(eps)\n\u001b[1;32m    307\u001b[0m param\u001b[39m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[39m=\u001b[39m\u001b[39m-\u001b[39mstep_size)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "step = 0\n",
        "\n",
        "tensor = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.Tensor\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    for d in datasets:\n",
        "        for split in splits:\n",
        "            data_loader = DataLoader( dataset=datasets[split], batch_size=BATCH_SIZE, shuffle = (split == \"train\") )\n",
        "\n",
        "            loss_tracker = defaultdict(tensor)\n",
        "\n",
        "            # Enable/Disable Dropout\n",
        "            if split == \"train\":\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "                target_tracker = []\n",
        "                pred_tracker = []\n",
        "\n",
        "            for iteration, batch in enumerate(data_loader):\n",
        "\n",
        "                for k, v in batch.items():\n",
        "                    batch[k] = v.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                logits, pred_probs = model(batch)\n",
        "\n",
        "                # loss calculation\n",
        "                loss = loss_criterion(logits, batch[\"fit\"])   # batch['fit'] are the true labels\n",
        "\n",
        "                # backward + optimization\n",
        "                if split == \"train\":\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    step += 1\n",
        "\n",
        "                # bookkeepeing\n",
        "                loss_tracker[\"Total Loss\"] = torch.cat((loss_tracker[\"Total Loss\"], loss.view(1)))\n",
        "\n",
        "                if iteration % 100 == 0 or iteration + 1 == len(data_loader):\n",
        "                    print(f\"{split.upper()} Batch Stats {iteration}/{len(data_loader)}, Loss={loss.item() :.2f}\")\n",
        "\n",
        "                if split == \"valid\":\n",
        "                    target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
        "                    pred_tracker.append(pred_probs.cpu().data.numpy())\n",
        "\n",
        "            print( f\"{split.upper()} Epoch {epoch + 1} / {EPOCHS}, Mean Total Loss {torch.mean(loss_tracker['Total Loss'])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_tracker = []\n",
        "pred_tracker = []\n",
        "\n",
        "print(\"Preparing test data ...\")\n",
        "\n",
        "data_loader = DataLoader(dataset = datasets['test'], batch_size = BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(\"Evaluating model on test data ...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "\n",
        "    for iteration, batch in enumerate(data_loader):\n",
        "\n",
        "        for k, v in batch.items():\n",
        "            batch[k] = v.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        _, pred_probs = model(batch)\n",
        "\n",
        "        target_tracker.append(batch[\"fit\"].cpu().numpy())\n",
        "        pred_tracker.append(pred_probs.cpu().data.numpy())\n",
        "\n",
        "target_tracker = np.stack(target_tracker[:-1]).reshape(-1)\n",
        "pred_tracker = np.stack(pred_tracker[:-1], axis=0).reshape(-1, NUM_TARGETS)\n",
        "precision, recall, f1_score, accuracy, auc = compute_metrics(target_tracker, pred_tracker, averaging = \"weighted\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(f\"Metrics:\\n Precision = {precision}\\n Recall = {recall}\\n F1-score = {f1_score}\\n Accuracy = {accuracy}\\n AUC = {auc}\\n \")\n",
        "print(\"-\" * 50)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.6 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "c1e5d2acd1631045f09d34790d51dde8c5f13a0de3f2ba4add1e385dbc0b204e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
